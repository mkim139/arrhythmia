{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm as tqdm \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_batch(in_num, out_num, kernel_size=5, padding=2, stride=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv1d(in_num, out_num, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
    "        nn.BatchNorm1d(out_num),\n",
    "        nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layer(self, block, in_channels, num_blocks):\n",
    "    layers = []\n",
    "    for i in range(0, num_blocks):\n",
    "        layers.append(block(in_channels))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, ks, pd):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        rc = int(np.ceil(in_channels/2))\n",
    "        self.layer1 = conv_batch(in_channels, rc, kernel_size=1, padding=0)\n",
    "        self.layer2 = conv_batch(rc, in_channels, kernel_size=ks, padding=pd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        residual = x\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNclassifier(nn.Module):\n",
    "    def __init__(self, block, num_classes):\n",
    "        super(CNNclassifier, self).__init__()\n",
    "        \n",
    "        #kernel 3 pad 1\n",
    "        self.k3_conv1 = conv_batch(1,36,kernel_size=3,padding=1,stride=1)\n",
    "        self.k3_conv2 = conv_batch(36,64,kernel_size=3,padding=1,stride=1)\n",
    "        self.k3_block1 = self.make_layer(block, in_channels=64, ks=3, pd=1, num_blocks=2)\n",
    "        self.k3_mp1 = nn.MaxPool1d(kernel_size=3,stride=2,padding=0)\n",
    "        self.k3_block2 = self.make_layer(block, in_channels=64, ks=3, pd=1, num_blocks=4)\n",
    "        self.k3_mp2 = nn.MaxPool1d(kernel_size=3,stride=3,padding=0)\n",
    "        self.k3_block3 = self.make_layer(block, in_channels=64, ks=3, pd=1, num_blocks=4)\n",
    "        self.k3_mp3 = nn.MaxPool1d(kernel_size=3,stride=3,padding=0)\n",
    "        self.k3_block4 = self.make_layer(block, in_channels=64, ks=3, pd=1, num_blocks=4)\n",
    "        self.k3_mp4 = nn.MaxPool1d(kernel_size=3,stride=3,padding=0)\n",
    "        self.k3_block5 = self.make_layer(block, in_channels=64, ks=3, pd=1, num_blocks=2)\n",
    "        self.k3_mp5 = nn.MaxPool1d(kernel_size=3,stride=2,padding=0)\n",
    "        \n",
    "        #kernel 5 pad 2\n",
    "        self.k5_conv1 = conv_batch(1,36,kernel_size=5,padding=2,stride=1)\n",
    "        self.k5_conv2 = conv_batch(36,64,kernel_size=5,padding=2,stride=1)\n",
    "        self.k5_block1 = self.make_layer(block, in_channels=64, ks=5, pd=2, num_blocks=2)\n",
    "        self.k5_mp1 = nn.MaxPool1d(kernel_size=5,stride=2,padding=0)\n",
    "        self.k5_block2 = self.make_layer(block, in_channels=64, ks=5, pd=2, num_blocks=4)\n",
    "        self.k5_mp2 = nn.MaxPool1d(kernel_size=5,stride=3,padding=0)\n",
    "        self.k5_block3 = self.make_layer(block, in_channels=64, ks=5, pd=2, num_blocks=4)\n",
    "        self.k5_mp3 = nn.MaxPool1d(kernel_size=5,stride=3,padding=0)\n",
    "        self.k5_block4 = self.make_layer(block, in_channels=64, ks=5, pd=2, num_blocks=4)\n",
    "        self.k5_mp4 = nn.MaxPool1d(kernel_size=5,stride=3,padding=0)\n",
    "        self.k5_block5 = self.make_layer(block, in_channels=64, ks=5, pd=2, num_blocks=2)\n",
    "        self.k5_mp5 = nn.MaxPool1d(kernel_size=5,stride=2,padding=0)\n",
    "\n",
    "        #kernel 7 pad 3\n",
    "        self.k7_conv1 = conv_batch(1,36,kernel_size=7,padding=3,stride=1)\n",
    "        self.k7_conv2 = conv_batch(36,64,kernel_size=7,padding=3,stride=1)\n",
    "        self.k7_block1 = self.make_layer(block, in_channels=64, ks=7, pd=3, num_blocks=2)\n",
    "        self.k7_mp1 = nn.MaxPool1d(kernel_size=7,stride=2,padding=0)\n",
    "        self.k7_block2 = self.make_layer(block, in_channels=64, ks=7, pd=3, num_blocks=4)\n",
    "        self.k7_mp2 = nn.MaxPool1d(kernel_size=7,stride=3,padding=0)\n",
    "        self.k7_block3 = self.make_layer(block, in_channels=64, ks=7, pd=3, num_blocks=4)\n",
    "        self.k7_mp3 = nn.MaxPool1d(kernel_size=7,stride=3,padding=0)\n",
    "        self.k7_block4 = self.make_layer(block, in_channels=64, ks=7, pd=3, num_blocks=4)\n",
    "        self.k7_mp4 = nn.MaxPool1d(kernel_size=7,stride=3,padding=0)\n",
    "        self.k7_block5 = self.make_layer(block, in_channels=64, ks=7, pd=3, num_blocks=2)\n",
    "        self.k7_mp5 = nn.MaxPool1d(kernel_size=7,stride=2,padding=0)\n",
    "        \n",
    "        #kernel 11 pad 5\n",
    "        self.k11_conv1 = conv_batch(1,36,kernel_size=11,padding=5,stride=1)\n",
    "        self.k11_conv2 = conv_batch(36,64,kernel_size=11,padding=5,stride=1)\n",
    "        self.k11_block1 = self.make_layer(block, in_channels=64, ks=11, pd=5, num_blocks=2)\n",
    "        self.k11_mp1 = nn.MaxPool1d(kernel_size=11,stride=2,padding=0)\n",
    "        self.k11_block2 = self.make_layer(block, in_channels=64, ks=11, pd=5, num_blocks=4)\n",
    "        self.k11_mp2 = nn.MaxPool1d(kernel_size=11,stride=3,padding=0)\n",
    "        self.k11_block3 = self.make_layer(block, in_channels=64, ks=11, pd=5, num_blocks=4)\n",
    "        self.k11_mp3 = nn.MaxPool1d(kernel_size=11,stride=3,padding=0)\n",
    "        self.k11_block4 = self.make_layer(block, in_channels=64, ks=11, pd=5, num_blocks=4)\n",
    "        self.k11_mp4 = nn.MaxPool1d(kernel_size=11,stride=3,padding=0)\n",
    "        self.k11_block5 = self.make_layer(block, in_channels=64, ks=11, pd=5, num_blocks=2)\n",
    "        self.k11_mp5 = nn.MaxPool1d(kernel_size=11,stride=2,padding=0)\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.Linear(70208,1280),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Dropout(.2),\n",
    "                                       nn.Linear(1280,128),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Dropout(.2),\n",
    "                                       nn.Linear(128,64),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Dropout(.2),\n",
    "                                       nn.Linear(64,num_classes),)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.k3_conv1(x)\n",
    "        out = self.k3_conv2(out)\n",
    "        out = self.k3_block1(out)\n",
    "        out = self.k3_mp1(out)\n",
    "        out = self.k3_block2(out)\n",
    "        out = self.k3_mp2(out)\n",
    "        out = self.k3_block3(out)\n",
    "        out = self.k3_mp3(out)\n",
    "        out = self.k3_block4(out)\n",
    "        out = self.k3_mp4(out)\n",
    "        out = self.k3_block5(out)\n",
    "        out1 = self.k3_mp5(out)\n",
    "        \n",
    "        out = self.k5_conv1(x)\n",
    "        out = self.k5_conv2(out)\n",
    "        out = self.k5_block1(out)\n",
    "        out = self.k5_mp1(out)\n",
    "        out = self.k5_block2(out)\n",
    "        out = self.k5_mp2(out)\n",
    "        out = self.k5_block3(out)\n",
    "        out = self.k5_mp3(out)\n",
    "        out = self.k5_block4(out)\n",
    "        out = self.k5_mp4(out)\n",
    "        out = self.k5_block5(out)\n",
    "        out2 = self.k5_mp5(out)\n",
    "        \n",
    "        out = self.k7_conv1(x)\n",
    "        out = self.k7_conv2(out)\n",
    "        out = self.k7_block1(out)\n",
    "        out = self.k7_mp1(out)\n",
    "        out = self.k7_block2(out)\n",
    "        out = self.k7_mp2(out)\n",
    "        out = self.k7_block3(out)\n",
    "        out = self.k7_mp3(out)\n",
    "        out = self.k7_block4(out)\n",
    "        out = self.k7_mp4(out)\n",
    "        out = self.k7_block5(out)\n",
    "        out3 = self.k7_mp5(out)\n",
    "        \n",
    "        out = self.k11_conv1(x)\n",
    "        out = self.k11_conv2(out)\n",
    "        out = self.k11_block1(out)\n",
    "        out = self.k11_mp1(out)\n",
    "        out = self.k11_block2(out)\n",
    "        out = self.k11_mp2(out)\n",
    "        out = self.k11_block3(out)\n",
    "        out = self.k11_mp3(out)\n",
    "        out = self.k11_block4(out)\n",
    "        out = self.k11_mp4(out)\n",
    "        out = self.k11_block5(out)\n",
    "        out4 = self.k11_mp5(out)\n",
    "        \n",
    "        out = torch.cat([out1.flatten(1),out2.flatten(1),out3.flatten(1),out4.flatten(1)],dim=1)\n",
    "        out = self.classifier(out)\n",
    "        out = torch.sigmoid(out.flatten())\n",
    "        return out\n",
    "    \n",
    "    def make_layer(self, block, in_channels, ks, pd, num_blocks):\n",
    "        layers = []\n",
    "        for i in range(0, num_blocks):\n",
    "            layers.append(block(in_channels, ks, pd))\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "model = CNNclassifier(ResidualBlock,num_classes)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Load\n",
    "train_Is = np.load('train_moreleads_noseg_Is3.npy')\n",
    "test_Is = np.load('test_moreleads_noseg_Is3.npy')\n",
    "train_IIs = np.load('train_moreleads_noseg_IIs3.npy')\n",
    "test_IIs = np.load('test_moreleads_noseg_IIs3.npy')\n",
    "train_IIIs = np.load('train_moreleads_noseg_IIIs3.npy')\n",
    "test_IIIs = np.load('test_moreleads_noseg_IIIs3.npy')\n",
    "train_aVRs = np.load('train_moreleads_noseg_aVRs3.npy')\n",
    "test_aVRs = np.load('test_moreleads_noseg_aVRs3.npy')\n",
    "train_aVLs = np.load('train_moreleads_noseg_aVLs3.npy')\n",
    "test_aVLs = np.load('test_moreleads_noseg_aVLs3.npy')\n",
    "train_aVFs = np.load('train_moreleads_noseg_aVFs3.npy')\n",
    "test_aVFs = np.load('test_moreleads_noseg_aVFs3.npy')\n",
    "\n",
    "train_y = (np.load('train_moreleads_noseg_labels3.npy')!=0)+0\n",
    "test_y = (np.load('test_moreleads_noseg_labels3.npy')!=0)+0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.hstack([train_Is,train_IIs,train_IIIs,train_aVRs,train_aVLs,train_aVFs])\n",
    "test_X = np.hstack([test_Is,test_IIs,test_IIIs,test_aVRs,test_aVLs,test_aVFs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train param\n",
    "num_epoch = 30\n",
    "batch_size = 16\n",
    "lr = .000005\n",
    "max_grad_norm = 0.5\n",
    "wei_dec = .0002\n",
    "log_interval = 200\n",
    "loss_fn = nn.BCELoss()\n",
    "model_name = 'model.pth'\n",
    "optimizer = optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay =wei_dec)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer,lr_lambda=lambda epoch: 0.95 ** epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, ecg, target):\n",
    "\n",
    "        self.target = torch.tensor(target).float()\n",
    "        self.ecg = torch.tensor(ecg).float()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.ecg[i], self.target[i])\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIdataset = Dataset(train_X,train_y)\n",
    "testIdataset = Dataset(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(trainIdataset, batch_size=batch_size,shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(testIdataset, batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trl = []\n",
    "ttl = []\n",
    "acc = []\n",
    "preci = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training scheme\n",
    "for i in range(num_epoch):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    #### Training\n",
    "    for batch_id, (x,y) in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x[:,np.newaxis,:].cuda())\n",
    "    \n",
    "        loss = loss_fn(out,y.cuda())\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        \n",
    "        lossavg = (loss/len(y)).data.cpu().numpy()\n",
    "        train_loss += lossavg\n",
    "        \n",
    "        if batch_id % log_interval == 0:\n",
    "            print('Epoch: ',i+1,' Batch ID: ',batch_id,' Train Loss: ',train_loss / (batch_id+1))\n",
    "        trl.append(train_loss / (batch_id+1))\n",
    "        \n",
    "        \n",
    "    #### Evaluation on Testset\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    acc_cnt = 0\n",
    "    cnt = 0\n",
    "    prec_cnt = 0\n",
    "    cnt2 = 0\n",
    "    for batch_id, (x,y) in enumerate(tqdm(test_dataloader)):\n",
    "        with torch.no_grad():\n",
    "            out = model(x[:,np.newaxis,:].cuda())\n",
    "\n",
    "            loss = loss_fn(out,y.cuda())\n",
    "\n",
    "            lossavg = (loss/len(y)).data.cpu().numpy()\n",
    "            cnt += len(y)\n",
    "            acc_cnt += sum((out > .5) == y.cuda())\n",
    "            cnt2 += sum(out > .5).detach().cpu()\n",
    "            prec_cnt += sum(y[out > .5])\n",
    "            test_loss += lossavg\n",
    "    print('epoch: ',i+1,' Test Loss: ',test_loss / (batch_id+1), 'Acc: ',(acc_cnt/cnt).item(),'Prec: ', (prec_cnt/cnt2).item())\n",
    "    if len(acc) > 0:\n",
    "        if max(acc) < (acc_cnt/cnt).item():\n",
    "            torch.save(model.state_dict(),model_name)\n",
    "    else : torch.save(model.state_dict(),model_name)\n",
    "    ttl.append((test_loss/ (batch_id+1)))\n",
    "    acc.append((acc_cnt/cnt).item())\n",
    "    preci.append((prec_cnt/cnt2).item())\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Best Model\n",
    "model.load_state_dict(torch.load(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#최종 정확도 측정\n",
    "model.eval()\n",
    "test_loss=0\n",
    "acc_cnt = 0\n",
    "cnt = 0\n",
    "prec_cnt = 0\n",
    "cnt2 = 0\n",
    "outs = []\n",
    "ys = []\n",
    "for batch_id, (x,y) in enumerate(tqdm(test_dataloader)):\n",
    "    with torch.no_grad():\n",
    "        out = model(x[:,np.newaxis,:].cuda())\n",
    "\n",
    "        loss = loss_fn(out,y.cuda())\n",
    "\n",
    "        lossavg = (loss/len(y)).data.cpu().numpy()\n",
    "        cnt += len(y)\n",
    "        acc_cnt += sum((out > .5) == y.cuda())\n",
    "        cnt2 += sum(out > .5).detach().cpu()\n",
    "        prec_cnt += sum(y[out > .5])\n",
    "        test_loss += lossavg\n",
    "        ys += y.tolist()\n",
    "        outs += out.detach().cpu().tolist()\n",
    "print('Acc: ',(acc_cnt/cnt).item(),'Prec: ', (prec_cnt/cnt2).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9972681323848072\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#AUC 계산\n",
    "plt.figure(figsize=(3,3))\n",
    "lab = np.array(ys)\n",
    "p = np.array(outs)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(lab, p, pos_label=1)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Postive Rate')\n",
    "plt.title('AUC')\n",
    "print('AUC: ',metrics.auc(fpr,tpr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
